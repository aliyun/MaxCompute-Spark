目前MaxCompute Spark支持以下几种运行方式：local模式，cluster模式，和在DataWorks中执行模式。

# Local模式
local模式可用于小批量数据以及计算本地验证，local模式验证通过后再提交到yarn-cluster模式

**说明** 
具体使用可参考[Local模式](https://github.com/aliyun/MaxCompute-Spark/wiki/02.-%E4%BD%BF%E7%94%A8Spark%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1(Local%E6%A8%A1%E5%BC%8F))

```
# /path/to/MaxCompute-Spark 请指向正确的编译出来后的application jar包
cd $SPARK_HOME
bin/spark-submit --master local[4] --class com.aliyun.odps.spark.examples.SparkPi \
/path/to/MaxCompute-Spark/spark-2.x/target/spark-examples_2.11-1.0.0-SNAPSHOT-shaded.jar
```

# Cluster模式
**说明** 
具体使用可参考[Yarn Cluster模式](https://github.com/aliyun/MaxCompute-Spark/wiki/02.-%E4%BD%BF%E7%94%A8Spark%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1(Yarn-Cluster%E6%A8%A1%E5%BC%8F))

```
# /path/to/MaxCompute-Spark 请指向正确的编译出来后的application jar包
cd $SPARK_HOME
bin/spark-submit --master yarn-cluster --class com.aliyun.odps.spark.examples.SparkPi \
/path/to/MaxCompute-Spark/spark-2.x/target/spark-examples_2.11-1.0.0-SNAPSHOT-shaded.jar
```

# DataWorks执行模式
Spark作业可以在DataWorks中进行调度，本质上也是采用了Yarn Cluster模式进行任务提交

**说明** 
具体使用可参考[Spark on Dataworks](https://github.com/aliyun/MaxCompute-Spark/wiki/02.-Spark-on-Dataworks)
